\chapter{Introduction\label{Introduction}}

Due to the vast amount of information available on the Internet today,
it is near impossible for researchers to have an 'up-to-date'
knowledge on anything but their own specific field. Even that seems
to become more and more difficult, as new information is added each
day\footnote{Take for instance the biomedical database MedLine that
  grows with over half a million citations per year}
\cite{CitAddMedLine}. Therefore it can be necessary to employ tools to
help gather, structure and look for relations or hypotheses within the
masses of information. One very popular method of finding new relations in
data is through the use of \textit{text mining}.

\begin{center}
{\small``The whole is greater than the sum of its parts'' $\sim$ Aristotle
(384--322 BC)} 
\end{center}

Text mining refers to the automated search for meaningful patterns in
structured or unstructured text documents, stored in very large digital
databases or distributed over the Web. A good example of this is
``Fish oil, Raynaud's syndrome and undiscovered public knowledge'' by
D.R. Swanson \cite{DRSwanson}. Here, Swanson was referring to published
knowledge buried deeply in disjoint topical domains\footnote{Here
  'disjoint' refers to articles written by researchers unaware of each
  others work}. Swanson was one of the first to propose using text
mining on biomedical literature. In 1986, he found evidence of a
relation between the use of fish oil and the development of Raynaud's
syndrome, by looking at seemingly unrelated documents. This was done
years before there actually were any scientific documents supporting
this.

Throughout recent years, the use of text mining has grown
tremendously. In the biomedical field, research is divided into highly
specialized sections and subsections, often too complex to enable for
interdisciplinary work. For instance, the recent sequencing of the
human genome has introduced a whole new level of detail to genetic
research. It is likely that new discoveries in this area could affect
other areas concerned with health and diseases, as genomic
mechanisms play a major role in the various branches of medicine
\cite{survey.biomed.text.cohen.2005}. Text mining is a way of making
these important connections in a world of increasing complexity and
hidden patterns. This method of making new, unseen discoveries also
introduces text mining as a major potential aid in the diagnosis of
rare or (to the physician) unknown diseases.

This project aims to make it easier and more efficient for physicians
to diagnose rare diseases. Through the use of text mining,
information retrieval and clustering algorithms, it attempts to
increase the likelihood of getting the correct article based upon a
search of symptoms, environmental and/or human factors. We use a list
of rare diseases and synonyms acquired from Rarediseases.info
\cite{Rarediseases}. Based on this, we
extract a series of MedLine records \cite{PubMedFactSheetMedline}
using the Python module Bio.Entrez \cite{EntrezProgUtil} and process
the text for a more optimized search.

\section{Inspiration}

The list of rare diseases numbers over 6,000 and increases by 5 each
week \cite{AboutRareDiseasesOrphanet}. A rare (or orphan) disease is
classified by the Orpha.net Encyclopedia \cite{OrphanetEncyclopedia}
as being a disease that affects less than 1 out of 2,000 people in
Europe, and which has severe chronic or terminal outcomes (or less
than 200,000 affected in the USA by standard of Rarediseases.info
\cite{Rarediseases}). Some of these \fxnote{fix - some of these
  diseases} diseases may not be fatal if treated promptly. However,
given the amount of knowledge a physician would need to carry
around to make a correct diagnosis (or correctly exclude other
potential candidates), quick (and correct) treatment isn't always the case.

When affected by a rare disease, the lack of a correct diagnosis
--- or the delay spent going from one specialist to another --- will
often lead to a fatal outcome. When it comes to rare, and often
dangerous diseases, the typical physician has little or no prior
experience with similar cases. It is therefore important that the
diagnosing physician has as much help at hand as possible in this
intrinsic task.

In a dialogue with Henrik L. J\o rgensen \cite{TheDude} --- chief
physician at Bispebjerg Hospital --- we found that --- even though
many systems already exist to help physicians in their diagnosis ---
there seemed to be a lack of a system for specifically diagnosing rare
diseases. Systems such as PubMed returns numerous results if the
symptoms are even slightly non-specific (more on this in the following
chapters). The advantage of a specialized system for rare diseases
would be that the physician --- when in doubt --- would have a chance
to quickly look the symptoms up, before referring or discharging the
patient. According to Henrik L. J\o rgensen, time is a great issue,
when treating patients and, in the rare event of a patient being
affected by something unknown, he or she is referred to a specialist.

The inspiring task of creating an efficient support decision
system for diagnosing rare diseases was what drove us to initiate this
project.

\section{Objectives}

\subsubsection{Aim}
Our system will be based on machine learning concepts and will
hopefully add something new to the arena of medical support decision
systems. Using various techniques to optimize our system, we aim to
design a system that --- if successful --- also has the generic potential of
being expanded to other domains than that of rare diseases.

\subsubsection{Overall process}
The list of rare disease names (along with synonyms and optional
descriptions) will be mined from the Rarediseases.info website. Some
of these diseases will have specialized PubMed search strings that we
mine along with the names. Using these names, predefined search
strings and synonyms, we search PubMed for a maximum of 500
PMID's\footnote{PMID's are unique article identifiers used by PubMed}
per disease, representing MedLine records containing an abstract. We
then download the corresponding records.

The intention is to preprocess the data using a vector space model and
various heuristics in order optimize the probability of getting a correct
hit. The heuristics are described in the following chapter but
revolve mainly around the Term Frequency - Inverse Document Frequency
(TF-IDF). Since a graphical user interface will not be made for the
prototype system, a correct hit is when an article defining the disease
is among the top 20 returned results from a given query of
symptoms.

We will be running tests on three different test cases. The first set
of cases are derived from a subset of tests in the BMJ article
\cite{HangwiTang11102006} relevant to our database\footnote{We only
  run tests on the diseases present in our database} The second set of
cases come from a random select of disease descriptions on the
Orpha.net website \cite{Orphanet}. The third and final set of test
cases come from a blind test provided by Henrik L. J\o rgensen.

\fxnote{tilfoej lennart hvis han kommer med noget}

\subsubsection{Primary tools}
We will be using Python 2.6.2 \cite{PythonLanguage} in this project. For access to PubMed, we use
the Python module Bio.Entrez \cite{EntrezProgUtil} while BeautifulSoup
\cite{BS} is used for parsing of HTML/XML combined with Urllib2
\cite{UL2} these are used for crawling the websites. For construction
of the term document matrix we use the SciPy package \cite{SciPy},
which supports sparse matrix structures. For auxiliary vector
functions we use the Numpy package \cite{NumPy}.

\section{Roadmap}

Chapter \ref{Background} covers the different databases that we
harvest our data from, and how we intend to model the
information. We provide a background on Rarediseases.info, PubMed and
the MedLine database, our primary data sources. We examine various
advantages and disadvantages of the models and heuristics that we use,
how we measure the similarities used to provide a disease score for
queries, we also look into the data types used to handle the large
amounts of information. Lastly, we look at an alternative that may
be able to provide more information on each mined disease.

Chapter \ref{Methods} deals with the methods that we have used to
implement the first prototype and the following branches of the
system. We present an overview of the implementation, amplify the
flexibility of the data exchange between the modules, and show how we
have applied several heuristics/filters to the data and the vector
space. The chapter finishes with details of the data and technical
discussion of the implementation.

Chapter \ref{ExperimentsResults} contains all the primary tests and
results of the different schemes used to find the most efficient model
for looking up rare diseases. The cosine similarity measure and the
simple sum similarity measure are tested, measured and put up against
each other to see which performs the best. This is done on both the
classical term document matrix and on a document-summed version called
the \textit{disease matrix}. It also deals with aspects and tests of
clustering and some of the potential noise in the data set.

Chapter \ref{Conclusion} is the conclusion of the project, it contains
a summary of the results, along with some comment on the usefulness of
a system such as this from Henrik L. J\o rgensen.


Chapter \ref{FutureWorks} contains future perspectives of the project,
what could it become and which features could be useful if the system
were to be made available for use by physicians all over the world.

